{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ee478c-9434-475c-96c0-1163e8e2294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31e617f-c412-455a-bd46-e487a810c519",
   "metadata": {},
   "source": [
    "# Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4951ea99-3476-46cf-99a6-3f361b5d760d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path =  /Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/coded-aperture/jornelasmunoz/\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from scipy.fft import fft2, ifft2, fft, ifft\n",
    "\n",
    "#from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "#import torch.nn as nn\n",
    "#import torch.nn.functional as F\n",
    "import wandb\n",
    "\n",
    "desktop_path = '/Users/jocelynornelasmunoz/Desktop/Research/coded-aperture/jornelasmunoz/'\n",
    "laptop_path = '/Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/coded-aperture/jornelasmunoz/'\n",
    "if desktop_path in sys.path[0]: sys.path.insert(0, desktop_path + 'lib/'); path = desktop_path\n",
    "elif laptop_path in sys.path[0]: sys.path.insert(0, laptop_path + 'lib/'); path = laptop_path\n",
    "print('Using path = ', path)\n",
    "#sys.path.insert(0, '/Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/coded-aperture/jornelasmunoz/lib/')\n",
    "import MURA as mura\n",
    "from CNN import CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45de13a4-1e8d-4c6c-8f2b-d10cea4462cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"Times\" #\"Computer Modern Serif\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e05c49da-b92e-42b7-87ae-c6d1d190878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13b95311-0f5e-4514-820b-7af1581849a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjocelynornelasmunoz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jocelynornelas/iCloud Drive (Archive)/Desktop/UC Merced/Research/coded-aperture/jornelasmunoz/notebooks/wandb/run-20221130_145204-3bdzsl4t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/jocelynornelasmunoz/coded-aperture-MNIST/runs/3bdzsl4t\" target=\"_blank\">rural-totem-28</a></strong> to <a href=\"https://wandb.ai/jocelynornelasmunoz/coded-aperture-MNIST\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/jocelynornelasmunoz/coded-aperture-MNIST/runs/3bdzsl4t?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f785920ef10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project=\"coded-aperture-MNIST\", group=\"2_convolutions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc41b3a4-5613-4d05-ad68-d25b228d8327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture a dictionary of hyperparameters with config\n",
    "params = {\n",
    " # \"dataset\": \"MNIST\",\n",
    " # \"machine\": \"desktop\",\n",
    " # \"model\": \"CNN -- 2 conv\",\n",
    "  \"learning_rate\": 1e-3,\n",
    "  \"batch_size\": 100,\n",
    "  \"epochs\": 50,\n",
    "}\n",
    "wandb.config = params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734f0ec2-62e8-43cd-95b9-631d9bbaf1cd",
   "metadata": {},
   "source": [
    "# Load MNIST Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6856974f-b8d4-425a-ad45-870fadeb6294",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "class FFT_convolve(object):\n",
    "   \n",
    "   #     Parameters\n",
    "   #    ----------\n",
    "   #   img: 2D numpy array\n",
    "   #         The original image with format of [c, h, w]\n",
    "   #     \n",
    "   # \n",
    "     \n",
    "    def __init__(self, A):\n",
    "        self.encoder = A\n",
    "        self.p = A.shape[0]\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        # Do convolution via FFT   \n",
    "        fft_A = torch.fft.fft2(self.A)\n",
    "        fft_img = torch.fft.fft2(img)\n",
    "        conv_Aimg = torch.real(torch.fft.ifft2(torch.mul(fft_A,fft_img)))\n",
    "        conv_Aimg = torch.roll(conv_Aimg, [int((self.p-1)/2),int((self.p-1)/2)], axis=(0,1))\n",
    "        #img = FFT_convolve(np.squeeze(img.numpy()), self.A, self.p)\n",
    "        #img = torch.unsqueeze(torch.tensor(img), 0)\n",
    "\n",
    "        return conv_Aimg#Image.fromarray(img)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__+'()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b761418f-ee7a-496a-8ef4-065251baa2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute MURA encoder and decoder\n",
    "p = 23 # size of array\n",
    "A = mura.create_binary_aperture_arr(p)\n",
    "G = mura.create_decoding_arr(A)\n",
    "\n",
    "# define CNN and get data\n",
    "model = CNN()\n",
    "train_data, test_data = model._get_dataset(A)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3) \n",
    "PATH = f'../models/mnist_{params[\"epochs\"]}epochs.pth'\n",
    "#wandb.watch(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d977b2cf-4caf-4d87-bb28-eededd7460d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=params['batch_size'], \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=0),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=params['batch_size'], \n",
    "                                          shuffle=False, \n",
    "                                          num_workers=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c738eca-37cf-4d0e-815f-0542d37b0a48",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab4da39d-aa54-443e-9448-1b3a75c51e57",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.112\n",
      "[1,   200] loss: 0.080\n",
      "[1,   300] loss: 0.052\n",
      "[1,   400] loss: 0.040\n",
      "[1,   500] loss: 0.032\n",
      "[1,   600] loss: 0.030\n",
      "[2,   100] loss: 0.026\n",
      "[2,   200] loss: 0.024\n",
      "[2,   300] loss: 0.021\n",
      "[2,   400] loss: 0.021\n",
      "[2,   500] loss: 0.018\n",
      "[2,   600] loss: 0.016\n",
      "[3,   100] loss: 0.017\n",
      "[3,   200] loss: 0.015\n",
      "[3,   300] loss: 0.015\n",
      "[3,   400] loss: 0.014\n",
      "[3,   500] loss: 0.015\n",
      "[3,   600] loss: 0.014\n",
      "[4,   100] loss: 0.012\n",
      "[4,   200] loss: 0.012\n",
      "[4,   300] loss: 0.012\n",
      "[4,   400] loss: 0.012\n",
      "[4,   500] loss: 0.012\n",
      "[4,   600] loss: 0.012\n",
      "[5,   100] loss: 0.011\n",
      "[5,   200] loss: 0.011\n",
      "[5,   300] loss: 0.010\n",
      "[5,   400] loss: 0.011\n",
      "[5,   500] loss: 0.011\n",
      "[5,   600] loss: 0.012\n",
      "[6,   100] loss: 0.011\n",
      "[6,   200] loss: 0.010\n",
      "[6,   300] loss: 0.010\n",
      "[6,   400] loss: 0.009\n",
      "[6,   500] loss: 0.010\n",
      "[6,   600] loss: 0.009\n",
      "[7,   100] loss: 0.009\n",
      "[7,   200] loss: 0.010\n",
      "[7,   300] loss: 0.009\n",
      "[7,   400] loss: 0.010\n",
      "[7,   500] loss: 0.009\n",
      "[7,   600] loss: 0.009\n",
      "[8,   100] loss: 0.009\n",
      "[8,   200] loss: 0.009\n",
      "[8,   300] loss: 0.008\n",
      "[8,   400] loss: 0.009\n",
      "[8,   500] loss: 0.009\n",
      "[8,   600] loss: 0.009\n",
      "[9,   100] loss: 0.008\n",
      "[9,   200] loss: 0.009\n",
      "[9,   300] loss: 0.009\n",
      "[9,   400] loss: 0.008\n",
      "[9,   500] loss: 0.008\n",
      "[9,   600] loss: 0.009\n",
      "[10,   100] loss: 0.008\n",
      "[10,   200] loss: 0.008\n",
      "[10,   300] loss: 0.007\n",
      "[10,   400] loss: 0.008\n",
      "[10,   500] loss: 0.008\n",
      "[10,   600] loss: 0.008\n",
      "[11,   100] loss: 0.007\n",
      "[11,   200] loss: 0.007\n",
      "[11,   300] loss: 0.007\n",
      "[11,   400] loss: 0.008\n",
      "[11,   500] loss: 0.008\n",
      "[11,   600] loss: 0.008\n",
      "[12,   100] loss: 0.007\n",
      "[12,   200] loss: 0.007\n",
      "[12,   300] loss: 0.007\n",
      "[12,   400] loss: 0.007\n",
      "[12,   500] loss: 0.007\n",
      "[12,   600] loss: 0.008\n",
      "[13,   100] loss: 0.006\n",
      "[13,   200] loss: 0.007\n",
      "[13,   300] loss: 0.006\n",
      "[13,   400] loss: 0.007\n",
      "[13,   500] loss: 0.007\n",
      "[13,   600] loss: 0.008\n",
      "[14,   100] loss: 0.006\n",
      "[14,   200] loss: 0.007\n",
      "[14,   300] loss: 0.006\n",
      "[14,   400] loss: 0.007\n",
      "[14,   500] loss: 0.007\n",
      "[14,   600] loss: 0.008\n",
      "[15,   100] loss: 0.006\n",
      "[15,   200] loss: 0.006\n",
      "[15,   300] loss: 0.006\n",
      "[15,   400] loss: 0.007\n",
      "[15,   500] loss: 0.006\n",
      "[15,   600] loss: 0.006\n",
      "[16,   100] loss: 0.006\n",
      "[16,   200] loss: 0.006\n",
      "[16,   300] loss: 0.006\n",
      "[16,   400] loss: 0.006\n",
      "[16,   500] loss: 0.006\n",
      "[16,   600] loss: 0.007\n",
      "[17,   100] loss: 0.006\n",
      "[17,   200] loss: 0.006\n",
      "[17,   300] loss: 0.006\n",
      "[17,   400] loss: 0.006\n",
      "[17,   500] loss: 0.006\n",
      "[17,   600] loss: 0.006\n",
      "[18,   100] loss: 0.005\n",
      "[18,   200] loss: 0.005\n",
      "[18,   300] loss: 0.007\n",
      "[18,   400] loss: 0.005\n",
      "[18,   500] loss: 0.006\n",
      "[18,   600] loss: 0.005\n",
      "[19,   100] loss: 0.005\n",
      "[19,   200] loss: 0.006\n",
      "[19,   300] loss: 0.005\n",
      "[19,   400] loss: 0.006\n",
      "[19,   500] loss: 0.006\n",
      "[19,   600] loss: 0.005\n",
      "[20,   100] loss: 0.005\n",
      "[20,   200] loss: 0.006\n",
      "[20,   300] loss: 0.005\n",
      "[20,   400] loss: 0.006\n",
      "[20,   500] loss: 0.005\n",
      "[20,   600] loss: 0.006\n",
      "[21,   100] loss: 0.005\n",
      "[21,   200] loss: 0.004\n",
      "[21,   300] loss: 0.005\n",
      "[21,   400] loss: 0.005\n",
      "[21,   500] loss: 0.005\n",
      "[21,   600] loss: 0.005\n",
      "[22,   100] loss: 0.005\n",
      "[22,   200] loss: 0.005\n",
      "[22,   300] loss: 0.004\n",
      "[22,   400] loss: 0.005\n",
      "[22,   500] loss: 0.005\n",
      "[22,   600] loss: 0.005\n",
      "[23,   100] loss: 0.004\n",
      "[23,   200] loss: 0.004\n",
      "[23,   300] loss: 0.004\n",
      "[23,   400] loss: 0.005\n",
      "[23,   500] loss: 0.005\n",
      "[23,   600] loss: 0.005\n",
      "[24,   100] loss: 0.005\n",
      "[24,   200] loss: 0.004\n",
      "[24,   300] loss: 0.005\n",
      "[24,   400] loss: 0.004\n",
      "[24,   500] loss: 0.005\n",
      "[24,   600] loss: 0.005\n",
      "[25,   100] loss: 0.004\n",
      "[25,   200] loss: 0.004\n",
      "[25,   300] loss: 0.005\n",
      "[25,   400] loss: 0.005\n",
      "[25,   500] loss: 0.004\n",
      "[25,   600] loss: 0.005\n",
      "[26,   100] loss: 0.004\n",
      "[26,   200] loss: 0.004\n",
      "[26,   300] loss: 0.004\n",
      "[26,   400] loss: 0.004\n",
      "[26,   500] loss: 0.004\n",
      "[26,   600] loss: 0.005\n",
      "[27,   100] loss: 0.004\n",
      "[27,   200] loss: 0.004\n",
      "[27,   300] loss: 0.004\n",
      "[27,   400] loss: 0.004\n",
      "[27,   500] loss: 0.004\n",
      "[27,   600] loss: 0.004\n",
      "[28,   100] loss: 0.004\n",
      "[28,   200] loss: 0.004\n",
      "[28,   300] loss: 0.004\n",
      "[28,   400] loss: 0.004\n",
      "[28,   500] loss: 0.004\n",
      "[28,   600] loss: 0.004\n",
      "[29,   100] loss: 0.003\n",
      "[29,   200] loss: 0.004\n",
      "[29,   300] loss: 0.004\n",
      "[29,   400] loss: 0.004\n",
      "[29,   500] loss: 0.004\n",
      "[29,   600] loss: 0.003\n",
      "[30,   100] loss: 0.003\n",
      "[30,   200] loss: 0.004\n",
      "[30,   300] loss: 0.003\n",
      "[30,   400] loss: 0.003\n",
      "[30,   500] loss: 0.004\n",
      "[30,   600] loss: 0.004\n",
      "[31,   100] loss: 0.003\n",
      "[31,   200] loss: 0.003\n",
      "[31,   300] loss: 0.004\n",
      "[31,   400] loss: 0.003\n",
      "[31,   500] loss: 0.004\n",
      "[31,   600] loss: 0.004\n",
      "[32,   100] loss: 0.004\n",
      "[32,   200] loss: 0.003\n",
      "[32,   300] loss: 0.004\n",
      "[32,   400] loss: 0.003\n",
      "[32,   500] loss: 0.004\n",
      "[32,   600] loss: 0.004\n",
      "[33,   100] loss: 0.003\n",
      "[33,   200] loss: 0.003\n",
      "[33,   300] loss: 0.004\n",
      "[33,   400] loss: 0.004\n",
      "[33,   500] loss: 0.004\n",
      "[33,   600] loss: 0.004\n",
      "[34,   100] loss: 0.003\n",
      "[34,   200] loss: 0.003\n",
      "[34,   300] loss: 0.003\n",
      "[34,   400] loss: 0.003\n",
      "[34,   500] loss: 0.003\n",
      "[34,   600] loss: 0.004\n",
      "[35,   100] loss: 0.003\n",
      "[35,   200] loss: 0.003\n",
      "[35,   300] loss: 0.004\n",
      "[35,   400] loss: 0.003\n",
      "[35,   500] loss: 0.003\n",
      "[35,   600] loss: 0.003\n",
      "[36,   100] loss: 0.003\n",
      "[36,   200] loss: 0.003\n",
      "[36,   300] loss: 0.003\n",
      "[36,   400] loss: 0.003\n",
      "[36,   500] loss: 0.004\n",
      "[36,   600] loss: 0.003\n",
      "[37,   100] loss: 0.003\n",
      "[37,   200] loss: 0.003\n",
      "[37,   300] loss: 0.004\n",
      "[37,   400] loss: 0.003\n",
      "[37,   500] loss: 0.003\n",
      "[37,   600] loss: 0.003\n",
      "[38,   100] loss: 0.003\n",
      "[38,   200] loss: 0.003\n",
      "[38,   300] loss: 0.003\n",
      "[38,   400] loss: 0.003\n",
      "[38,   500] loss: 0.002\n",
      "[38,   600] loss: 0.003\n",
      "[39,   100] loss: 0.003\n",
      "[39,   200] loss: 0.004\n",
      "[39,   300] loss: 0.003\n",
      "[39,   400] loss: 0.003\n",
      "[39,   500] loss: 0.003\n",
      "[39,   600] loss: 0.003\n",
      "[40,   100] loss: 0.002\n",
      "[40,   200] loss: 0.002\n",
      "[40,   300] loss: 0.003\n",
      "[40,   400] loss: 0.003\n",
      "[40,   500] loss: 0.003\n",
      "[40,   600] loss: 0.003\n",
      "[41,   100] loss: 0.002\n",
      "[41,   200] loss: 0.002\n",
      "[41,   300] loss: 0.003\n",
      "[41,   400] loss: 0.003\n",
      "[41,   500] loss: 0.004\n",
      "[41,   600] loss: 0.003\n",
      "[42,   100] loss: 0.002\n",
      "[42,   200] loss: 0.002\n",
      "[42,   300] loss: 0.002\n",
      "[42,   400] loss: 0.004\n",
      "[42,   500] loss: 0.003\n",
      "[42,   600] loss: 0.003\n",
      "[43,   100] loss: 0.002\n",
      "[43,   200] loss: 0.002\n",
      "[43,   300] loss: 0.002\n",
      "[43,   400] loss: 0.002\n",
      "[43,   500] loss: 0.002\n",
      "[43,   600] loss: 0.002\n",
      "[44,   100] loss: 0.002\n",
      "[44,   200] loss: 0.002\n",
      "[44,   300] loss: 0.002\n",
      "[44,   400] loss: 0.003\n",
      "[44,   500] loss: 0.003\n",
      "[44,   600] loss: 0.002\n",
      "[45,   100] loss: 0.002\n",
      "[45,   200] loss: 0.002\n",
      "[45,   300] loss: 0.003\n",
      "[45,   400] loss: 0.002\n",
      "[45,   500] loss: 0.003\n",
      "[45,   600] loss: 0.002\n",
      "[46,   100] loss: 0.002\n",
      "[46,   200] loss: 0.002\n",
      "[46,   300] loss: 0.003\n",
      "[46,   400] loss: 0.003\n",
      "[46,   500] loss: 0.002\n",
      "[46,   600] loss: 0.003\n",
      "[47,   100] loss: 0.002\n",
      "[47,   200] loss: 0.002\n",
      "[47,   300] loss: 0.003\n",
      "[47,   400] loss: 0.002\n",
      "[47,   500] loss: 0.002\n",
      "[47,   600] loss: 0.002\n",
      "[48,   100] loss: 0.002\n",
      "[48,   200] loss: 0.003\n",
      "[48,   300] loss: 0.002\n",
      "[48,   400] loss: 0.002\n",
      "[48,   500] loss: 0.003\n",
      "[48,   600] loss: 0.003\n",
      "[49,   100] loss: 0.003\n",
      "[49,   200] loss: 0.002\n",
      "[49,   300] loss: 0.003\n",
      "[49,   400] loss: 0.002\n",
      "[49,   500] loss: 0.002\n",
      "[49,   600] loss: 0.002\n",
      "[50,   100] loss: 0.002\n",
      "[50,   200] loss: 0.002\n",
      "[50,   300] loss: 0.002\n",
      "[50,   400] loss: 0.002\n",
      "[50,   500] loss: 0.001\n",
      "[50,   600] loss: 0.003\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33b31e7bdae40e197c6795d24b2e71f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>loss</td><td>█▅▂▁▃▂▁▂▂▁▂▂▁▂▂▁▂▂▁▂▂▁▂▂▁▁▂▁▁▁▁▁▂▁▁▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rural-totem-28</strong>: <a href=\"https://wandb.ai/jocelynornelasmunoz/coded-aperture-MNIST/runs/3bdzsl4t\" target=\"_blank\">https://wandb.ai/jocelynornelasmunoz/coded-aperture-MNIST/runs/3bdzsl4t</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221130_145204-3bdzsl4t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in range(params['epochs']):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(loaders['train']):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "        wandb.log({\"epoch\": epoch, \"loss\": running_loss})\n",
    "print('Finished Training')\n",
    "# Save model\n",
    "\n",
    "torch.save(model.state_dict(), PATH)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed40ed9-75ed-412e-ad89-fdc1db0a478b",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87df8d42-1109-43a7-a5be-d76f08275544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model if one is not loaded already\n",
    "#PATH = '../models/mnist_net.pth'\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02f557d0-b2ec-4aa8-801b-a874b9efa1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(loaders['test'])\n",
    "images, labels = dataiter.next()\n",
    "outputs = model(images)\n",
    "_, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e79ca77-4421-4013-ad0f-9a1ac8a21e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in loaders['test']:\n",
    "        images, labels = data\n",
    "    \n",
    "        # calculate outputs by running images through the network (done in batches)\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "178f8d8d-7052-4123-bd8a-a1206be12c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class:     0 is 97.9 %\n",
      "Accuracy for class:     1 is 98.8 %\n",
      "Accuracy for class:     2 is 95.9 %\n",
      "Accuracy for class:     3 is 93.6 %\n",
      "Accuracy for class:     4 is 95.8 %\n",
      "Accuracy for class:     5 is 92.2 %\n",
      "Accuracy for class:     6 is 97.4 %\n",
      "Accuracy for class:     7 is 93.5 %\n",
      "Accuracy for class:     8 is 93.4 %\n",
      "Accuracy for class:     9 is 94.4 %\n"
     ]
    }
   ],
   "source": [
    "classes = [i for i in range(10)]\n",
    "# prepare to count predictions for each class\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in loaders['test']:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[int(label.numpy())] += 1\n",
    "            total_pred[int(label.numpy())] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(f'Accuracy for class: {classname:5d} is {accuracy:.1f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb61feeb-9b00-4f7f-a483-74fffd736ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 0\n",
    "img = images[index][0]\n",
    "true_img = mura.FFT_convolve(img.numpy(), G)\n",
    "pred_lab = predicted[index]\n",
    "true_lab = labels[index]\n",
    "\n",
    "fig, axs = plt.subplots(1,2, figsize=(10,7))\n",
    "axs = axs.ravel()\n",
    "axs[0].imshow(img)\n",
    "axs[1].imshow(true_img)\n",
    "axs[0].set_title(f\"True label: {true_lab} \\n Predicted label: {pred_lab}\")\n",
    "axs[1].set_title(\"Decoded image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72383b9c-6a16-474c-86e6-cc023480649f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294ad918-1c19-4935-b8c7-ccbe24ae8ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5996718-9b66-4052-8242-49f12aab6ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3546a-dca7-48f4-92df-2cde711a9b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd95fd1e-fac4-4e63-bb62-ef0b1c4d43e7",
   "metadata": {},
   "source": [
    "# To be deleted"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df46078f-a8a8-494a-83f1-eeb671c1202f",
   "metadata": {},
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.kernel = 3\n",
    "        # 1 input image channel, 8 output channels, 2x2 square convolution kernel\n",
    "        self.conv1 = nn.Conv2d(1, 8, self.kernel)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(8, 16, self.kernel)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        #x = (F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 16 * 4* 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a0c07151-68a1-4aa1-ac11-c47a0b0c340f",
   "metadata": {},
   "source": [
    "# Compute MURA encoder and decoder\n",
    "p = 23 # size of array\n",
    "A = mura.create_binary_aperture_arr(p)\n",
    "G = mura.create_decoding_arr(A)\n",
    "\n",
    "# fig, axs = plt.subplots(1,2)\n",
    "# axs = axs.ravel()\n",
    "# axs[0].imshow(A, cmap='gray')\n",
    "# axs[1].imshow(G, cmap='gray')\n",
    "# axs[0].set_title(\"Encoder\")\n",
    "# axs[1].set_title(\"Decoder\")\n",
    "# plt.show()\n",
    "\n",
    "# Load training and testing data from PyTorch\n",
    "size = A.shape[0]\n",
    "train_data = datasets.MNIST(\n",
    "    root = '../data/',\n",
    "    train = True,                         \n",
    "    transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize(size),\n",
    "                    #transforms.Normalize(mean=0., std=(1/255.)),\n",
    "                    # Apply MURA encoder\n",
    "                    transforms.Lambda(lambda x: torch.unsqueeze(torch.tensor(mura.FFT_convolve(np.squeeze(x.numpy()), A,p), dtype= torch.float), 0)),\n",
    "                    #transforms.Lambda(mura.get_D),\n",
    "                    transforms.Normalize(0, 1)\n",
    "                ]), \n",
    "    download = False,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = '../data/', \n",
    "    train = False, \n",
    "    transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize(size),\n",
    "                    #transforms.Normalize(mean=0., std=(1/255.)),\n",
    "                    # Apply MURA encoder\n",
    "                    #transforms.Lambda(mura.get_D),\n",
    "                    transforms.Lambda(lambda x: torch.unsqueeze(torch.tensor(mura.FFT_convolve(np.squeeze(x.numpy()), A,p), dtype= torch.float), 0)),\n",
    "                    transforms.Normalize(0, 1)\n",
    "                ]) \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
