{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38dd060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0a0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../lib')\n",
    "# from CNN import CNN\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5d5df79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, img_shape = 28, conv_layers = 2, num_classes = 10):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "#         self.conv_count = 0   #keeps track of the number of times a conv layer is added\n",
    "        self.img_shape = img_shape   \n",
    "        self.num_classes = num_classes\n",
    "        self.conv_layers = conv_layers\n",
    "        self.root_path = '../data/28x28'\n",
    "        self.ker_size = 0\n",
    "        self.padding = 0\n",
    "        self.out_channels = 0\n",
    "        self.linear_shape = [1, img_shape, img_shape]\n",
    "        self.conv = []\n",
    "        \n",
    "        \n",
    "        def conv_out_size(linear_shape, img_shape, conv):\n",
    "            linear_shape[0] = conv[0].out_channels\n",
    "            linear_shape[1] = int(( (img_shape - conv[0].kernel_size[0] + 2*conv[0].padding[0]) / conv[0].stride[0]) + 1)\n",
    "            img_shape = linear_shape[1]\n",
    "            linear_shape[2] = linear_shape[1]\n",
    "\n",
    "            return linear_shape, img_shape\n",
    "\n",
    "\n",
    "        def pooling_out_size(linear_shape, img_shape, conv):\n",
    "            linear_shape[1] = int(( (img_shape - conv[2].kernel_size) / conv[2].stride) + 1)\n",
    "            img_shape = linear_shape[1]\n",
    "            linear_shape[2] = linear_shape[1]\n",
    "\n",
    "            return linear_shape, img_shape\n",
    "\n",
    "        def flatten(linear_shape):\n",
    "            return linear_shape[0] * linear_shape[1] * linear_shape[2]\n",
    "        \n",
    "        \n",
    "        def load_data(img_shape, root_path):\n",
    "            train_data = datasets.MNIST(\n",
    "                root = root_path,\n",
    "                train = True,                         \n",
    "                transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Resize(img_shape),\n",
    "                                transforms.Normalize(0, 1)\n",
    "                            ]), \n",
    "                download = False,            \n",
    "            )\n",
    "            test_data = datasets.MNIST(\n",
    "                root = '../data/28x28', \n",
    "                train = False, \n",
    "                transform = transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Resize(img_shape),\n",
    "                                transforms.Normalize(0, 1)\n",
    "                            ]) \n",
    "            )\n",
    "            \n",
    "            return train_data, test_data\n",
    "        \n",
    "        \n",
    "        # Loading training and testing data\n",
    "        self.train_data, self.test_data = load_data(self.img_shape, self.root_path)\n",
    "        \n",
    "        self.loaders = {\n",
    "            'train' : torch.utils.data.DataLoader(self.train_data, \n",
    "                                                  batch_size=100, \n",
    "                                                  shuffle=True, \n",
    "                                                  num_workers=1),\n",
    "\n",
    "            'test'  : torch.utils.data.DataLoader(self.test_data, \n",
    "                                                  batch_size=100, \n",
    "                                                  shuffle=True, \n",
    "                                                  num_workers=1),\n",
    "        }\n",
    "        \n",
    "        if self.img_shape == 28:\n",
    "            self.out_channels = 16\n",
    "            self.ker_size = 5\n",
    "        \n",
    "        elif self.img_shape == 14:\n",
    "            self.out_channels = 8\n",
    "            self.ker_size = 3\n",
    "            \n",
    "        elif self.img_shape == 7:\n",
    "            self.out_channels = 4\n",
    "            self.ker_size = 2\n",
    "            \n",
    "        elif self.img_shape == 4:\n",
    "            self.out_channels = 4\n",
    "            self.ker_size = 3\n",
    "            self.padding = 1\n",
    "        \n",
    "        for i in range(conv_layers):\n",
    "#             ker_size = 5\n",
    "#             padding = 0\n",
    "            if not self.conv:\n",
    "                layer = nn.Sequential(         \n",
    "                    nn.Conv2d(\n",
    "                        in_channels=1,              \n",
    "                        out_channels=self.out_channels,            \n",
    "                        kernel_size=self.ker_size,              \n",
    "                        stride=1,                   \n",
    "                        padding=self.padding,                  \n",
    "                    ),                              \n",
    "                    nn.ReLU(),                      \n",
    "                    nn.MaxPool2d(kernel_size=2),    \n",
    "                )\n",
    "                \n",
    "            else:\n",
    "                layer = nn.Sequential(         \n",
    "                    nn.Conv2d(\n",
    "                        in_channels = self.conv[i-1][0].out_channels,              \n",
    "                        out_channels = self.conv[i-1][0].out_channels * 2,            \n",
    "                        kernel_size = self.ker_size,              \n",
    "                        stride = 1,                   \n",
    "                        padding=self.padding,                  \n",
    "                    ),                              \n",
    "                    nn.ReLU(),                      \n",
    "                    nn.MaxPool2d(kernel_size=2),    \n",
    "                )\n",
    "            \n",
    "            self.conv.append(layer)\n",
    "#             self.conv_count += 1\n",
    "            \n",
    "            self.linear_shape, self.img_shape = conv_out_size(self.linear_shape, self.img_shape, self.conv[i])\n",
    "            self.linear_shape, self.img_shape = pooling_out_size(self.linear_shape, self.img_shape, self.conv[i])\n",
    "            \n",
    "#             if self.img_shape <= 0 and self.ker_size >= 2:\n",
    "#                 self.ker_size -= 1\n",
    "#                 i = -1\n",
    "#                 self.img_shape = img_shape\n",
    "#                 print(\"executed!!\")\n",
    "            \n",
    "#             print(\"ker_size = \", self.ker_size)\n",
    "            \n",
    "#             elif img_shape == 0 and padding == 0:\n",
    "#                 padding += 1\n",
    "#                 i = -1\n",
    "#                 self.img_shape = img_shape\n",
    "#                 print(img_shape)\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        # input to Linear layer MUST be an integer!!\n",
    "        self.out_shape = int(flatten(self.linear_shape))\n",
    "        self.out = nn.Linear(self.out_shape, self.num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i in range(len(self.conv)):\n",
    "            x = self.conv[i](x)\n",
    "            \n",
    "        # flatten the output of conv2 to (batch_size, 32 * 4 * 4)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization\n",
    "    \n",
    "    \n",
    "\n",
    "def train(cnn, loaders, num_epochs=10):\n",
    "    loss_func = nn.CrossEntropyLoss()   \n",
    "    optimizer = torch.optim.Adam(cnn.parameters(), lr= 1e-5)\n",
    "    \n",
    "    cnn.train()\n",
    "    \n",
    "    train_acc_data = []\n",
    "    loss_data = []\n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # measure accuracy and record loss\n",
    "            train_output, last_layer = cnn(images)\n",
    "            pred_y = torch.max(train_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), accuracy))\n",
    "                \n",
    "            if (i+1) % 600 == 0:\n",
    "                train_acc_data.append(accuracy)\n",
    "                loss_data.append(loss)\n",
    "            pass\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9945f62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=512, out_features=10, bias=True)\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(img_shape=28)\n",
    "print(cnn.out)\n",
    "print(cnn.img_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a4489320",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/600], Loss: 2.3014, Accuracy: 0.1700\n",
      "Epoch [1/10], Step [200/600], Loss: 2.2899, Accuracy: 0.2000\n",
      "Epoch [1/10], Step [300/600], Loss: 2.2859, Accuracy: 0.1900\n",
      "Epoch [1/10], Step [400/600], Loss: 2.2777, Accuracy: 0.1600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [500/600], Loss: 2.2627, Accuracy: 0.2300\n",
      "Epoch [1/10], Step [600/600], Loss: 2.2654, Accuracy: 0.2600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [100/600], Loss: 2.2561, Accuracy: 0.2900\n",
      "Epoch [2/10], Step [200/600], Loss: 2.2396, Accuracy: 0.4200\n",
      "Epoch [2/10], Step [300/600], Loss: 2.2311, Accuracy: 0.3900\n",
      "Epoch [2/10], Step [400/600], Loss: 2.2347, Accuracy: 0.3700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Step [500/600], Loss: 2.2168, Accuracy: 0.5100\n",
      "Epoch [2/10], Step [600/600], Loss: 2.2004, Accuracy: 0.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [100/600], Loss: 2.2011, Accuracy: 0.5200\n",
      "Epoch [3/10], Step [200/600], Loss: 2.2014, Accuracy: 0.4900\n",
      "Epoch [3/10], Step [300/600], Loss: 2.1935, Accuracy: 0.5200\n",
      "Epoch [3/10], Step [400/600], Loss: 2.1970, Accuracy: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Step [500/600], Loss: 2.1795, Accuracy: 0.5900\n",
      "Epoch [3/10], Step [600/600], Loss: 2.1617, Accuracy: 0.5800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [100/600], Loss: 2.1579, Accuracy: 0.6400\n",
      "Epoch [4/10], Step [200/600], Loss: 2.1575, Accuracy: 0.6600\n",
      "Epoch [4/10], Step [300/600], Loss: 2.1451, Accuracy: 0.6600\n",
      "Epoch [4/10], Step [400/600], Loss: 2.1517, Accuracy: 0.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Step [500/600], Loss: 2.1173, Accuracy: 0.7100\n",
      "Epoch [4/10], Step [600/600], Loss: 2.1146, Accuracy: 0.7100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [100/600], Loss: 2.1127, Accuracy: 0.7100\n",
      "Epoch [5/10], Step [200/600], Loss: 2.1058, Accuracy: 0.7200\n",
      "Epoch [5/10], Step [300/600], Loss: 2.1070, Accuracy: 0.6900\n",
      "Epoch [5/10], Step [400/600], Loss: 2.0773, Accuracy: 0.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Step [500/600], Loss: 2.0829, Accuracy: 0.6800\n",
      "Epoch [5/10], Step [600/600], Loss: 2.0817, Accuracy: 0.7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [100/600], Loss: 2.0672, Accuracy: 0.6900\n",
      "Epoch [6/10], Step [200/600], Loss: 2.0546, Accuracy: 0.7400\n",
      "Epoch [6/10], Step [300/600], Loss: 2.0435, Accuracy: 0.7200\n",
      "Epoch [6/10], Step [400/600], Loss: 2.0479, Accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Step [500/600], Loss: 2.0481, Accuracy: 0.7600\n",
      "Epoch [6/10], Step [600/600], Loss: 2.0047, Accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [100/600], Loss: 2.0463, Accuracy: 0.7300\n",
      "Epoch [7/10], Step [200/600], Loss: 2.0207, Accuracy: 0.7400\n",
      "Epoch [7/10], Step [300/600], Loss: 1.9818, Accuracy: 0.7900\n",
      "Epoch [7/10], Step [400/600], Loss: 1.9924, Accuracy: 0.7900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Step [500/600], Loss: 2.0232, Accuracy: 0.6900\n",
      "Epoch [7/10], Step [600/600], Loss: 1.9762, Accuracy: 0.7400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [100/600], Loss: 1.9973, Accuracy: 0.7300\n",
      "Epoch [8/10], Step [200/600], Loss: 1.9680, Accuracy: 0.7900\n",
      "Epoch [8/10], Step [300/600], Loss: 1.9553, Accuracy: 0.7600\n",
      "Epoch [8/10], Step [400/600], Loss: 1.9306, Accuracy: 0.8200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Step [500/600], Loss: 1.9238, Accuracy: 0.7900\n",
      "Epoch [8/10], Step [600/600], Loss: 1.9880, Accuracy: 0.6300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [100/600], Loss: 1.9090, Accuracy: 0.7600\n",
      "Epoch [9/10], Step [200/600], Loss: 1.9484, Accuracy: 0.7700\n",
      "Epoch [9/10], Step [300/600], Loss: 1.9319, Accuracy: 0.7500\n",
      "Epoch [9/10], Step [400/600], Loss: 1.8961, Accuracy: 0.7700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Step [500/600], Loss: 1.8705, Accuracy: 0.8400\n",
      "Epoch [9/10], Step [600/600], Loss: 1.8989, Accuracy: 0.7700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee166c1860>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [100/600], Loss: 1.9344, Accuracy: 0.7400\n",
      "Epoch [10/10], Step [200/600], Loss: 1.9237, Accuracy: 0.6800\n",
      "Epoch [10/10], Step [300/600], Loss: 1.8913, Accuracy: 0.7800\n",
      "Epoch [10/10], Step [400/600], Loss: 1.8942, Accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method _MultiProcessingDataLoaderIter.__del__ of <torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x7fee3b6a0898>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 1320, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/multiprocessing/process.py\", line 134, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Step [500/600], Loss: 1.8518, Accuracy: 0.8100\n",
      "Epoch [10/10], Step [600/600], Loss: 1.8455, Accuracy: 0.7500\n",
      "CPU times: user 4min 2s, sys: 25.1 s, total: 4min 27s\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_model(cnn, cnn.loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ae6e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1631631159818/work/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# There was something Jocelyn did to modify the image sizes without modifying the dtype\n",
    "size = [28, 14, 7, 4]\n",
    "train_data = [None] * 4\n",
    "test_data = [None] * 4\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    train_data[i] = datasets.MNIST(\n",
    "        root = '../data/4x4',\n",
    "        train = True,                         \n",
    "        transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Resize(size[i]),\n",
    "                        transforms.Normalize(0, 1)\n",
    "                    ]), \n",
    "        download = False,            \n",
    "    )\n",
    "    test_data[i] = datasets.MNIST(\n",
    "        root = '../data/4x4', \n",
    "        train = False, \n",
    "        transform = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Resize(size[i]),\n",
    "                        transforms.Normalize(0, 1)\n",
    "                    ]),\n",
    "        download = False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d70b568",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd960e12160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[0][0][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd506a",
   "metadata": {},
   "source": [
    "<h3>MNIST Dataset is organized by:</h3>\n",
    "<div>Set of images (with channels) and labels --> train_data</div>\n",
    "<div>image (with channels) AND label --> train_data[i (0,59999)]</div>\n",
    "<div>image (with channels) --> train_data[i][i (0,1)]</div>\n",
    "<div>image by itself (2D image) --> train_data[i][i][i (0)]</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5592a361",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 \n",
      "\n",
      "\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../data/4x4\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "               Resize(size=28, interpolation=bilinear, max_size=None, antialias=None)\n",
      "               Normalize(mean=0, std=1)\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# Images and labels are stored as a tuple (image, label)\n",
    "\n",
    "print(len(train_data[0]), '\\n\\n')\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2b86e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../data/4x4\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Resize(size=28, interpolation=bilinear, max_size=None, antialias=None)\n",
       "               Normalize(mean=0, std=1)\n",
       "           )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b044cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc4b42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the entire dataset\n",
    "# train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "811d6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints one image\n",
    "# train_data[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "025495f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints one array of pixels (not the entire image)\n",
    "# train_data[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9bf47c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(train_data[1][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9963265",
   "metadata": {},
   "source": [
    "<h1>Using Pytorch's Data loaders to feed data into CNN</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2388d129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d035c82bf49c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m loaders = {\n\u001b[0;32m----> 2\u001b[0;31m     'train' : torch.utils.data.DataLoader(train_data, \n\u001b[0m\u001b[1;32m      3\u001b[0m                                           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                           \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           num_workers=1),\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ecff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experimenting\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab257c6",
   "metadata": {},
   "source": [
    "<h1>Defining the models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe59cb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = []\n",
    "\n",
    "for i in range(len(size)):\n",
    "    cnn.append(CNN(size[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6acac17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(cnn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62626944",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = []\n",
    "loss_func = nn.CrossEntropyLoss()   \n",
    "\n",
    "for i in range(len(cnn)):\n",
    "    optimizer.append( torch.optim.Adam(cnn[i].parameters(), lr= 1e-5) )\n",
    "\n",
    "# print(loss_func)\n",
    "# print(optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba8cd7",
   "metadata": {},
   "source": [
    "<h1>Training the CNN</h1>\n",
    "<div>Error source may be that the dataset resized_28 doesn't have 'labels', just 'images' ---> (for i, (images, labels))</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e420aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = [75, 75, 125, 200]\n",
    "train_acc_data = []\n",
    "test_acc_data = []\n",
    "loss_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b8b6368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2ce80d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, cnn, loaders):\n",
    "    for j in range(len(cnn)):\n",
    "        cnn[j].train()\n",
    "\n",
    "        # Train the model\n",
    "        total_step = len(loaders['train'])\n",
    "\n",
    "        for epoch in range(num_epochs[j]):\n",
    "            for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "                # gives batch data, normalize x when iterate train_loader\n",
    "                b_x = Variable(images)   # batch x\n",
    "                b_y = Variable(labels)   # batch y\n",
    "                output = cnn[j](b_x)[0]               \n",
    "                loss = loss_func(output, b_y)\n",
    "\n",
    "                # measure accuracy and record loss\n",
    "                train_output, last_layer = cnn[j](images)\n",
    "                pred_y = torch.max(train_output, 1)[1].data.squeeze()\n",
    "                accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "\n",
    "                # clear gradients for this training step   \n",
    "                optimizer.zero_grad()           \n",
    "\n",
    "                # backpropagation, compute gradients \n",
    "                loss.backward()    \n",
    "                # apply gradients             \n",
    "                optimizer.step()  \n",
    "    #             output = cnn(images)\n",
    "    #             correct += (output == labels).float().sum()\n",
    "    #             accuracy = 100 * correct / len(trainset)\n",
    "\n",
    "                if (i+1) % 100 == 0:\n",
    "                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.4f}' \n",
    "                           .format(epoch + 1, num_epochs, i + 1, total_step, loss.item(), accuracy))\n",
    "\n",
    "                if(i+1) % 600 == 0:\n",
    "                    train_acc_data.append(accuracy)\n",
    "                    loss_data.append(loss)\n",
    "\n",
    "                pass\n",
    "\n",
    "            pass\n",
    "\n",
    "\n",
    "        pass\n",
    "\n",
    "def test():\n",
    "    for j in range(len(cnn)):\n",
    "        cnn[j].eval()\n",
    "\n",
    "        # Train the model\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn[j](images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "            test_acc_data.append(accuracy)\n",
    "            print(\"Accuracy: {:.4f}\".format(accuracy))\n",
    "\n",
    "    #     print('Test Accuracy: %.2f' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d074388f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 86, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found torchvision.datasets.mnist.MNIST\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-df596c0cddc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-6d50e3d5f72e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(num_epochs, cnn, loaders)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0;31m# gives batch data, normalize x when iterate train_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1201\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1227\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1229\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# have message field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 287, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 47, in fetch\n    return self.collate_fn(data)\n  File \"/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torch/utils/data/_utils/collate.py\", line 86, in default_collate\n    raise TypeError(default_collate_err_msg_format.format(elem_type))\nTypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found torchvision.datasets.mnist.MNIST\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce692476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61821df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(acc_data)):\n",
    "#     if acc_data[i] == 0.71:\n",
    "#         print(\"fount at \", i)\n",
    "\n",
    "# acc_data[600-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a23eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,3, figsize=(20, 5))\n",
    "axarr[0].set_title(\"Train Accuracy\")\n",
    "axarr[0].set_xlabel(\"Epochs\")\n",
    "axarr[0].set_ylabel(\"Accuracy\")\n",
    "axarr[0].plot(train_acc_data)\n",
    "\n",
    "axarr[1].set_title(\"Test Accuracy\")\n",
    "axarr[1].set_xlabel(\"Batch #\")\n",
    "axarr[1].set_ylabel(\"Accuracy\")\n",
    "axarr[1].plot(test_acc_data)\n",
    "\n",
    "\n",
    "axarr[2].set_title(\"Loss\")\n",
    "axarr[2].set_xlabel(\"Epochs\")\n",
    "axarr[2].set_ylabel(\"Loss Value\")\n",
    "axarr[2].plot(loss_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3728ba4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn.train()\n",
    "len(loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd065c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48401ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(resized_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c165e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, image in enumerate(loaders['train']):\n",
    "#     print(i, image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d586d001",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798469f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figwidth(8)\n",
    "fig.set_figheight(30)\n",
    "plt.imshow(test_data[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e05d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
