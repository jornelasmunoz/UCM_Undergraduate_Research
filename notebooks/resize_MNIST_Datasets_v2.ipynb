{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3613af00-2330-4960-b295-c72980a88bc9",
   "metadata": {},
   "source": [
    "# CNN Class pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a22e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015cfd9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db127a5-56a0-4a2b-ac94-d3afe5055536",
   "metadata": {},
   "source": [
    "# Get training and testing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f15bc7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22.9%%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%/opt/anaconda3/envs/PyTorch/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-7w1l4mea/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(\n",
    "    root = '../data',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root = '../data', \n",
    "    train = False, \n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd16c158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ../data\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print metadata of train_data\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0449d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one of the training samples\n",
    "index = 2\n",
    "plt.imshow(train_data.data[index], cmap='gray')\n",
    "plt.title('%i' % train_data.targets[index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c863b364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7fd7d371f5e0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7fd7be8df340>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create loaders \n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'test'  : torch.utils.data.DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}\n",
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2f7ed07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b139fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5f2c501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()   \n",
    "loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f29afe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.01\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)   \n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c85fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "            \n",
    "            # gives batch data, normalize x when iterate train_loader\n",
    "            b_x = Variable(images)   # batch x\n",
    "            b_y = Variable(labels)   # batch y\n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "            pass\n",
    "        \n",
    "        pass\n",
    "    \n",
    "    \n",
    "    pass\n",
    "# train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9930321f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e15f4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torchvision/datasets/mnist.py:52: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8292ccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristianespinosa/opt/anaconda3/envs/tensor/lib/python3.6/site-packages/torchvision/datasets/mnist.py:57: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3923be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: data\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f18a7919",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = [28, 14, 7, 4]\n",
    "i = 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.resize(train_data.data[0], (IMG_SIZE[i], IMG_SIZE[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
